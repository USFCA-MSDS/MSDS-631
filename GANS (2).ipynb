{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Networks (GANs)\n",
        "\n",
        "Generative Adversarial Networks (GANs) are a type of deep learning framework that have revolutionized the field of generative modeling. GANs consist of two main components: a generator network and a discriminator network. The objective of GANs is to train the generator network to produce realistic synthetic data that is indistinguishable from real data, while the discriminator network aims to distinguish between the generated and real data.\n",
        "\n",
        "The generator network takes random noise as input and generates synthetic data samples. Initially, the generated samples may not resemble the real data. The discriminator network, on the other hand, is trained to distinguish between the generated samples and real data samples. It tries to classify whether a given sample is real or fake. The generator and discriminator networks are trained iteratively in a competitive manner, playing a min-max game.\n",
        "\n",
        "During training, the generator tries to improve its ability to generate realistic samples that can fool the discriminator, while the discriminator tries to become more accurate in distinguishing between real and fake samples. This adversarial game between the generator and discriminator leads to a dynamic equilibrium, where the generator progressively generates more realistic samples and the discriminator becomes more discerning.\n",
        "\n",
        "The ultimate goal of GANs is to train the generator network to produce synthetic samples that are so close to real data that even the discriminator cannot distinguish them. This is achieved by updating the generator and discriminator networks alternately using gradient-based optimization techniques.\n",
        "\n",
        "GANs have gained popularity due to their ability to generate highly realistic and diverse data, including images, videos, and even text. They have been used for various applications such as image synthesis, data augmentation, style transfer, and image-to-image translation.\n",
        "\n",
        " GANs can be thought of as a **game** between two competing networks. The generator network learns to produce realistic synthetic data to fool the discriminator, while the discriminator network aims to accurately distinguish between real and fake samples. This adversarial game drives the GAN training process and leads to the generation of high-quality synthetic data.\n"
      ],
      "metadata": {
        "id": "ae-NgkEVLX3F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IW6vLrZnAKnh",
        "outputId": "0dd16429-6d18-42ec-bf2e-7ad0a6fc02e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Step [100/469], Generator Loss: 2.6834, Discriminator Loss: 0.1132\n",
            "Epoch [1/50], Step [200/469], Generator Loss: 5.0509, Discriminator Loss: 0.0105\n",
            "Epoch [1/50], Step [300/469], Generator Loss: 3.4948, Discriminator Loss: 0.1870\n",
            "Epoch [1/50], Step [400/469], Generator Loss: 4.6189, Discriminator Loss: 0.1960\n",
            "Epoch [2/50], Step [100/469], Generator Loss: 8.6057, Discriminator Loss: 0.0448\n",
            "Epoch [2/50], Step [200/469], Generator Loss: 4.1978, Discriminator Loss: 0.0659\n",
            "Epoch [2/50], Step [300/469], Generator Loss: 3.4050, Discriminator Loss: 0.0631\n",
            "Epoch [2/50], Step [400/469], Generator Loss: 4.3219, Discriminator Loss: 0.0683\n",
            "Epoch [3/50], Step [100/469], Generator Loss: 5.8372, Discriminator Loss: 0.0618\n",
            "Epoch [3/50], Step [200/469], Generator Loss: 1.5942, Discriminator Loss: 0.4668\n",
            "Epoch [3/50], Step [300/469], Generator Loss: 3.9848, Discriminator Loss: 0.0507\n",
            "Epoch [3/50], Step [400/469], Generator Loss: 3.5677, Discriminator Loss: 0.4104\n",
            "Epoch [4/50], Step [100/469], Generator Loss: 3.0756, Discriminator Loss: 0.3074\n",
            "Epoch [4/50], Step [200/469], Generator Loss: 2.6477, Discriminator Loss: 0.3267\n",
            "Epoch [4/50], Step [300/469], Generator Loss: 2.2371, Discriminator Loss: 0.3373\n",
            "Epoch [4/50], Step [400/469], Generator Loss: 3.8189, Discriminator Loss: 0.2447\n",
            "Epoch [5/50], Step [100/469], Generator Loss: 4.5109, Discriminator Loss: 0.3899\n",
            "Epoch [5/50], Step [200/469], Generator Loss: 2.3311, Discriminator Loss: 0.5101\n",
            "Epoch [5/50], Step [300/469], Generator Loss: 4.0970, Discriminator Loss: 0.6652\n",
            "Epoch [5/50], Step [400/469], Generator Loss: 3.5320, Discriminator Loss: 0.4845\n",
            "Epoch [6/50], Step [100/469], Generator Loss: 2.4339, Discriminator Loss: 0.4601\n",
            "Epoch [6/50], Step [200/469], Generator Loss: 2.6044, Discriminator Loss: 0.4709\n",
            "Epoch [6/50], Step [300/469], Generator Loss: 4.1176, Discriminator Loss: 0.1270\n",
            "Epoch [6/50], Step [400/469], Generator Loss: 4.7630, Discriminator Loss: 0.0513\n",
            "Epoch [7/50], Step [100/469], Generator Loss: 2.5016, Discriminator Loss: 0.1379\n",
            "Epoch [7/50], Step [200/469], Generator Loss: 3.2269, Discriminator Loss: 0.1300\n",
            "Epoch [7/50], Step [300/469], Generator Loss: 4.7384, Discriminator Loss: 0.3087\n",
            "Epoch [7/50], Step [400/469], Generator Loss: 3.5889, Discriminator Loss: 0.0664\n",
            "Epoch [8/50], Step [100/469], Generator Loss: 4.2370, Discriminator Loss: 0.0555\n",
            "Epoch [8/50], Step [200/469], Generator Loss: 6.5376, Discriminator Loss: 0.1032\n",
            "Epoch [8/50], Step [300/469], Generator Loss: 5.9848, Discriminator Loss: 0.0717\n",
            "Epoch [8/50], Step [400/469], Generator Loss: 4.3965, Discriminator Loss: 0.1488\n",
            "Epoch [9/50], Step [100/469], Generator Loss: 4.2551, Discriminator Loss: 0.1173\n",
            "Epoch [9/50], Step [200/469], Generator Loss: 3.1465, Discriminator Loss: 0.1460\n",
            "Epoch [9/50], Step [300/469], Generator Loss: 4.6288, Discriminator Loss: 0.1521\n",
            "Epoch [9/50], Step [400/469], Generator Loss: 4.8094, Discriminator Loss: 0.0553\n",
            "Epoch [10/50], Step [100/469], Generator Loss: 6.9620, Discriminator Loss: 0.2028\n",
            "Epoch [10/50], Step [200/469], Generator Loss: 5.5802, Discriminator Loss: 0.0266\n",
            "Epoch [10/50], Step [300/469], Generator Loss: 6.2990, Discriminator Loss: 0.0852\n",
            "Epoch [10/50], Step [400/469], Generator Loss: 7.4596, Discriminator Loss: 0.1425\n",
            "Epoch [11/50], Step [100/469], Generator Loss: 4.4474, Discriminator Loss: 0.0759\n",
            "Epoch [11/50], Step [200/469], Generator Loss: 4.6993, Discriminator Loss: 0.0976\n",
            "Epoch [11/50], Step [300/469], Generator Loss: 6.6366, Discriminator Loss: 0.0368\n",
            "Epoch [11/50], Step [400/469], Generator Loss: 5.6330, Discriminator Loss: 0.0440\n",
            "Epoch [12/50], Step [100/469], Generator Loss: 5.9900, Discriminator Loss: 0.0636\n",
            "Epoch [12/50], Step [200/469], Generator Loss: 5.2824, Discriminator Loss: 0.0700\n",
            "Epoch [12/50], Step [300/469], Generator Loss: 4.4806, Discriminator Loss: 0.2392\n",
            "Epoch [12/50], Step [400/469], Generator Loss: 6.3170, Discriminator Loss: 0.1113\n",
            "Epoch [13/50], Step [100/469], Generator Loss: 4.2492, Discriminator Loss: 0.1944\n",
            "Epoch [13/50], Step [200/469], Generator Loss: 4.4171, Discriminator Loss: 0.0876\n",
            "Epoch [13/50], Step [300/469], Generator Loss: 6.2651, Discriminator Loss: 0.1530\n",
            "Epoch [13/50], Step [400/469], Generator Loss: 6.0296, Discriminator Loss: 0.0690\n",
            "Epoch [14/50], Step [100/469], Generator Loss: 6.6170, Discriminator Loss: 0.1906\n",
            "Epoch [14/50], Step [200/469], Generator Loss: 5.0897, Discriminator Loss: 0.1134\n",
            "Epoch [14/50], Step [300/469], Generator Loss: 3.2693, Discriminator Loss: 0.2885\n",
            "Epoch [14/50], Step [400/469], Generator Loss: 3.0132, Discriminator Loss: 0.2559\n",
            "Epoch [15/50], Step [100/469], Generator Loss: 4.4436, Discriminator Loss: 0.1124\n",
            "Epoch [15/50], Step [200/469], Generator Loss: 3.4304, Discriminator Loss: 0.1602\n",
            "Epoch [15/50], Step [300/469], Generator Loss: 4.1943, Discriminator Loss: 0.1644\n",
            "Epoch [15/50], Step [400/469], Generator Loss: 3.2104, Discriminator Loss: 0.1069\n",
            "Epoch [16/50], Step [100/469], Generator Loss: 5.1046, Discriminator Loss: 0.0901\n",
            "Epoch [16/50], Step [200/469], Generator Loss: 4.1080, Discriminator Loss: 0.0701\n",
            "Epoch [16/50], Step [300/469], Generator Loss: 5.3653, Discriminator Loss: 0.2289\n",
            "Epoch [16/50], Step [400/469], Generator Loss: 5.6581, Discriminator Loss: 0.2466\n",
            "Epoch [17/50], Step [100/469], Generator Loss: 4.0870, Discriminator Loss: 0.1227\n",
            "Epoch [17/50], Step [200/469], Generator Loss: 5.0229, Discriminator Loss: 0.1723\n",
            "Epoch [17/50], Step [300/469], Generator Loss: 4.2362, Discriminator Loss: 0.1755\n",
            "Epoch [17/50], Step [400/469], Generator Loss: 6.6640, Discriminator Loss: 0.0609\n",
            "Epoch [18/50], Step [100/469], Generator Loss: 3.3006, Discriminator Loss: 0.2173\n",
            "Epoch [18/50], Step [200/469], Generator Loss: 5.7183, Discriminator Loss: 0.1960\n",
            "Epoch [18/50], Step [300/469], Generator Loss: 3.7091, Discriminator Loss: 0.1477\n",
            "Epoch [18/50], Step [400/469], Generator Loss: 4.9915, Discriminator Loss: 0.1521\n",
            "Epoch [19/50], Step [100/469], Generator Loss: 5.6808, Discriminator Loss: 0.1588\n",
            "Epoch [19/50], Step [200/469], Generator Loss: 4.3058, Discriminator Loss: 0.2421\n",
            "Epoch [19/50], Step [300/469], Generator Loss: 5.0092, Discriminator Loss: 0.2634\n",
            "Epoch [19/50], Step [400/469], Generator Loss: 3.5534, Discriminator Loss: 0.2294\n",
            "Epoch [20/50], Step [100/469], Generator Loss: 4.3419, Discriminator Loss: 0.1946\n",
            "Epoch [20/50], Step [200/469], Generator Loss: 5.7167, Discriminator Loss: 0.1180\n",
            "Epoch [20/50], Step [300/469], Generator Loss: 3.9147, Discriminator Loss: 0.2564\n",
            "Epoch [20/50], Step [400/469], Generator Loss: 6.2561, Discriminator Loss: 0.2029\n",
            "Epoch [21/50], Step [100/469], Generator Loss: 2.8542, Discriminator Loss: 0.4568\n",
            "Epoch [21/50], Step [200/469], Generator Loss: 4.6822, Discriminator Loss: 0.3010\n",
            "Epoch [21/50], Step [300/469], Generator Loss: 4.1103, Discriminator Loss: 0.0693\n",
            "Epoch [21/50], Step [400/469], Generator Loss: 3.3182, Discriminator Loss: 0.1860\n",
            "Epoch [22/50], Step [100/469], Generator Loss: 4.3610, Discriminator Loss: 0.3195\n",
            "Epoch [22/50], Step [200/469], Generator Loss: 4.8601, Discriminator Loss: 0.2195\n",
            "Epoch [22/50], Step [300/469], Generator Loss: 4.7217, Discriminator Loss: 0.1549\n",
            "Epoch [22/50], Step [400/469], Generator Loss: 4.5869, Discriminator Loss: 0.2406\n",
            "Epoch [23/50], Step [100/469], Generator Loss: 5.7734, Discriminator Loss: 0.0936\n",
            "Epoch [23/50], Step [200/469], Generator Loss: 3.9400, Discriminator Loss: 0.1806\n",
            "Epoch [23/50], Step [300/469], Generator Loss: 3.7078, Discriminator Loss: 0.3252\n",
            "Epoch [23/50], Step [400/469], Generator Loss: 5.0934, Discriminator Loss: 0.1478\n",
            "Epoch [24/50], Step [100/469], Generator Loss: 2.7562, Discriminator Loss: 0.2628\n",
            "Epoch [24/50], Step [200/469], Generator Loss: 4.5316, Discriminator Loss: 0.2055\n",
            "Epoch [24/50], Step [300/469], Generator Loss: 6.0035, Discriminator Loss: 0.1920\n",
            "Epoch [24/50], Step [400/469], Generator Loss: 3.7323, Discriminator Loss: 0.2007\n",
            "Epoch [25/50], Step [100/469], Generator Loss: 3.9528, Discriminator Loss: 0.1999\n",
            "Epoch [25/50], Step [200/469], Generator Loss: 3.5539, Discriminator Loss: 0.1841\n",
            "Epoch [25/50], Step [300/469], Generator Loss: 5.2398, Discriminator Loss: 0.0625\n",
            "Epoch [25/50], Step [400/469], Generator Loss: 3.9766, Discriminator Loss: 0.1750\n",
            "Epoch [26/50], Step [100/469], Generator Loss: 4.1546, Discriminator Loss: 0.1912\n",
            "Epoch [26/50], Step [200/469], Generator Loss: 6.0984, Discriminator Loss: 0.4296\n",
            "Epoch [26/50], Step [300/469], Generator Loss: 4.0929, Discriminator Loss: 0.2082\n",
            "Epoch [26/50], Step [400/469], Generator Loss: 3.3396, Discriminator Loss: 0.1797\n",
            "Epoch [27/50], Step [100/469], Generator Loss: 3.6832, Discriminator Loss: 0.2790\n",
            "Epoch [27/50], Step [200/469], Generator Loss: 3.2990, Discriminator Loss: 0.2454\n",
            "Epoch [27/50], Step [300/469], Generator Loss: 5.1004, Discriminator Loss: 0.1444\n",
            "Epoch [27/50], Step [400/469], Generator Loss: 4.5366, Discriminator Loss: 0.0932\n",
            "Epoch [28/50], Step [100/469], Generator Loss: 4.1760, Discriminator Loss: 0.1827\n",
            "Epoch [28/50], Step [200/469], Generator Loss: 4.2480, Discriminator Loss: 0.1729\n",
            "Epoch [28/50], Step [300/469], Generator Loss: 2.8389, Discriminator Loss: 0.2145\n",
            "Epoch [28/50], Step [400/469], Generator Loss: 3.7002, Discriminator Loss: 0.2422\n",
            "Epoch [29/50], Step [100/469], Generator Loss: 4.6631, Discriminator Loss: 0.1364\n",
            "Epoch [29/50], Step [200/469], Generator Loss: 4.5836, Discriminator Loss: 0.2033\n",
            "Epoch [29/50], Step [300/469], Generator Loss: 4.2065, Discriminator Loss: 0.4857\n",
            "Epoch [29/50], Step [400/469], Generator Loss: 3.7949, Discriminator Loss: 0.2934\n",
            "Epoch [30/50], Step [100/469], Generator Loss: 3.2248, Discriminator Loss: 0.2354\n",
            "Epoch [30/50], Step [200/469], Generator Loss: 3.9019, Discriminator Loss: 0.2619\n",
            "Epoch [30/50], Step [300/469], Generator Loss: 5.5847, Discriminator Loss: 0.3052\n",
            "Epoch [30/50], Step [400/469], Generator Loss: 3.3789, Discriminator Loss: 0.2777\n",
            "Epoch [31/50], Step [100/469], Generator Loss: 4.4082, Discriminator Loss: 0.1685\n",
            "Epoch [31/50], Step [200/469], Generator Loss: 4.7002, Discriminator Loss: 0.3693\n",
            "Epoch [31/50], Step [300/469], Generator Loss: 3.9129, Discriminator Loss: 0.2263\n",
            "Epoch [31/50], Step [400/469], Generator Loss: 3.8187, Discriminator Loss: 0.1873\n",
            "Epoch [32/50], Step [100/469], Generator Loss: 3.6675, Discriminator Loss: 0.1855\n",
            "Epoch [32/50], Step [200/469], Generator Loss: 3.0270, Discriminator Loss: 0.2620\n",
            "Epoch [32/50], Step [300/469], Generator Loss: 4.3666, Discriminator Loss: 0.2664\n",
            "Epoch [32/50], Step [400/469], Generator Loss: 4.0132, Discriminator Loss: 0.2554\n",
            "Epoch [33/50], Step [100/469], Generator Loss: 4.2829, Discriminator Loss: 0.3383\n",
            "Epoch [33/50], Step [200/469], Generator Loss: 4.8291, Discriminator Loss: 0.2650\n",
            "Epoch [33/50], Step [300/469], Generator Loss: 5.8064, Discriminator Loss: 0.4021\n",
            "Epoch [33/50], Step [400/469], Generator Loss: 4.3694, Discriminator Loss: 0.1527\n",
            "Epoch [34/50], Step [100/469], Generator Loss: 5.2966, Discriminator Loss: 0.2101\n",
            "Epoch [34/50], Step [200/469], Generator Loss: 2.9352, Discriminator Loss: 0.3504\n",
            "Epoch [34/50], Step [300/469], Generator Loss: 2.8434, Discriminator Loss: 0.3121\n",
            "Epoch [34/50], Step [400/469], Generator Loss: 5.5064, Discriminator Loss: 0.2839\n",
            "Epoch [35/50], Step [100/469], Generator Loss: 4.1508, Discriminator Loss: 0.3064\n",
            "Epoch [35/50], Step [200/469], Generator Loss: 4.6193, Discriminator Loss: 0.2272\n",
            "Epoch [35/50], Step [300/469], Generator Loss: 4.0733, Discriminator Loss: 0.1945\n",
            "Epoch [35/50], Step [400/469], Generator Loss: 4.2788, Discriminator Loss: 0.1869\n",
            "Epoch [36/50], Step [100/469], Generator Loss: 3.7308, Discriminator Loss: 0.2289\n",
            "Epoch [36/50], Step [200/469], Generator Loss: 4.0768, Discriminator Loss: 0.3342\n",
            "Epoch [36/50], Step [300/469], Generator Loss: 3.2582, Discriminator Loss: 0.2247\n",
            "Epoch [36/50], Step [400/469], Generator Loss: 3.5035, Discriminator Loss: 0.3373\n",
            "Epoch [37/50], Step [100/469], Generator Loss: 3.3340, Discriminator Loss: 0.3546\n",
            "Epoch [37/50], Step [200/469], Generator Loss: 4.2298, Discriminator Loss: 0.1685\n",
            "Epoch [37/50], Step [300/469], Generator Loss: 4.0012, Discriminator Loss: 0.2567\n",
            "Epoch [37/50], Step [400/469], Generator Loss: 3.3685, Discriminator Loss: 0.3286\n",
            "Epoch [38/50], Step [100/469], Generator Loss: 2.7699, Discriminator Loss: 0.3844\n",
            "Epoch [38/50], Step [200/469], Generator Loss: 2.6786, Discriminator Loss: 0.5159\n",
            "Epoch [38/50], Step [300/469], Generator Loss: 2.5386, Discriminator Loss: 0.4651\n",
            "Epoch [38/50], Step [400/469], Generator Loss: 3.8716, Discriminator Loss: 0.3647\n",
            "Epoch [39/50], Step [100/469], Generator Loss: 3.9153, Discriminator Loss: 0.5130\n",
            "Epoch [39/50], Step [200/469], Generator Loss: 3.2848, Discriminator Loss: 0.4163\n",
            "Epoch [39/50], Step [300/469], Generator Loss: 2.9890, Discriminator Loss: 0.2976\n",
            "Epoch [39/50], Step [400/469], Generator Loss: 3.6069, Discriminator Loss: 0.3623\n",
            "Epoch [40/50], Step [100/469], Generator Loss: 3.7900, Discriminator Loss: 0.1637\n",
            "Epoch [40/50], Step [200/469], Generator Loss: 3.5110, Discriminator Loss: 0.2304\n",
            "Epoch [40/50], Step [300/469], Generator Loss: 3.6040, Discriminator Loss: 0.3047\n",
            "Epoch [40/50], Step [400/469], Generator Loss: 3.3557, Discriminator Loss: 0.3209\n",
            "Epoch [41/50], Step [100/469], Generator Loss: 2.1685, Discriminator Loss: 0.5161\n",
            "Epoch [41/50], Step [200/469], Generator Loss: 3.4240, Discriminator Loss: 0.2779\n",
            "Epoch [41/50], Step [300/469], Generator Loss: 3.5737, Discriminator Loss: 0.2602\n",
            "Epoch [41/50], Step [400/469], Generator Loss: 3.5634, Discriminator Loss: 0.2551\n",
            "Epoch [42/50], Step [100/469], Generator Loss: 3.2811, Discriminator Loss: 0.2258\n",
            "Epoch [42/50], Step [200/469], Generator Loss: 4.9374, Discriminator Loss: 0.2379\n",
            "Epoch [42/50], Step [300/469], Generator Loss: 3.1291, Discriminator Loss: 0.2505\n",
            "Epoch [42/50], Step [400/469], Generator Loss: 3.3738, Discriminator Loss: 0.4491\n",
            "Epoch [43/50], Step [100/469], Generator Loss: 4.4423, Discriminator Loss: 0.3290\n",
            "Epoch [43/50], Step [200/469], Generator Loss: 3.2959, Discriminator Loss: 0.3185\n",
            "Epoch [43/50], Step [300/469], Generator Loss: 3.4212, Discriminator Loss: 0.2073\n",
            "Epoch [43/50], Step [400/469], Generator Loss: 4.2294, Discriminator Loss: 0.2812\n",
            "Epoch [44/50], Step [100/469], Generator Loss: 2.9905, Discriminator Loss: 0.3241\n",
            "Epoch [44/50], Step [200/469], Generator Loss: 3.9362, Discriminator Loss: 0.3244\n",
            "Epoch [44/50], Step [300/469], Generator Loss: 3.0550, Discriminator Loss: 0.3433\n",
            "Epoch [44/50], Step [400/469], Generator Loss: 3.4382, Discriminator Loss: 0.3182\n",
            "Epoch [45/50], Step [100/469], Generator Loss: 3.0866, Discriminator Loss: 0.2664\n",
            "Epoch [45/50], Step [200/469], Generator Loss: 3.8389, Discriminator Loss: 0.4218\n",
            "Epoch [45/50], Step [300/469], Generator Loss: 3.5163, Discriminator Loss: 0.3614\n",
            "Epoch [45/50], Step [400/469], Generator Loss: 2.5737, Discriminator Loss: 0.3285\n",
            "Epoch [46/50], Step [100/469], Generator Loss: 3.0264, Discriminator Loss: 0.2690\n",
            "Epoch [46/50], Step [200/469], Generator Loss: 3.6921, Discriminator Loss: 0.2514\n",
            "Epoch [46/50], Step [300/469], Generator Loss: 2.5703, Discriminator Loss: 0.4107\n",
            "Epoch [46/50], Step [400/469], Generator Loss: 3.5409, Discriminator Loss: 0.6264\n",
            "Epoch [47/50], Step [100/469], Generator Loss: 2.8389, Discriminator Loss: 0.4084\n",
            "Epoch [47/50], Step [200/469], Generator Loss: 3.7188, Discriminator Loss: 0.3618\n",
            "Epoch [47/50], Step [300/469], Generator Loss: 2.4963, Discriminator Loss: 0.4224\n",
            "Epoch [47/50], Step [400/469], Generator Loss: 2.4394, Discriminator Loss: 0.4176\n",
            "Epoch [48/50], Step [100/469], Generator Loss: 3.4463, Discriminator Loss: 0.4406\n",
            "Epoch [48/50], Step [200/469], Generator Loss: 4.0759, Discriminator Loss: 0.3009\n",
            "Epoch [48/50], Step [300/469], Generator Loss: 2.7022, Discriminator Loss: 0.3506\n",
            "Epoch [48/50], Step [400/469], Generator Loss: 2.9939, Discriminator Loss: 0.4240\n",
            "Epoch [49/50], Step [100/469], Generator Loss: 2.4555, Discriminator Loss: 0.4612\n",
            "Epoch [49/50], Step [200/469], Generator Loss: 2.7700, Discriminator Loss: 0.3442\n",
            "Epoch [49/50], Step [300/469], Generator Loss: 2.9424, Discriminator Loss: 0.3783\n",
            "Epoch [49/50], Step [400/469], Generator Loss: 2.9625, Discriminator Loss: 0.2982\n",
            "Epoch [50/50], Step [100/469], Generator Loss: 3.0563, Discriminator Loss: 0.3243\n",
            "Epoch [50/50], Step [300/469], Generator Loss: 3.2995, Discriminator Loss: 0.4214\n",
            "Epoch [50/50], Step [400/469], Generator Loss: 2.1666, Discriminator Loss: 0.4941\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Set device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define hyperparameters\n",
        "batch_size = 128\n",
        "latent_size = 100\n",
        "num_epochs = 50\n",
        "learning_rate = 0.0002\n",
        "\n",
        "# MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
        "])\n",
        "\n",
        "mnist_data = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "\n",
        "        self.fc1 = nn.Linear(latent_size, 256)\n",
        "        self.fc2 = nn.Linear(256, 512)\n",
        "        self.fc3 = nn.Linear(512, 784)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.output = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.output(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 1)\n",
        "        self.activation = nn.LeakyReLU(0.2)\n",
        "        self.output = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.output(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Create the generator and discriminator\n",
        "generator = Generator(latent_size).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Loss function and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (real_images, _) in enumerate(data_loader):\n",
        "        real_images = real_images.to(device)\n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        # Create labels for real and fake images\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # Train the generator\n",
        "        optimizer_G.zero_grad()\n",
        "        z = torch.randn(batch_size, latent_size).to(device)\n",
        "        fake_images = generator(z)\n",
        "        outputs = discriminator(fake_images)\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Train the discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "        real_outputs = discriminator(real_images)\n",
        "        d_real_loss = criterion(real_outputs, real_labels)\n",
        "        fake_outputs = discriminator(fake_images.detach())\n",
        "        d_fake_loss = criterion(fake_outputs, fake_labels)\n",
        "        d_loss = d_real_loss + d_fake_loss\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(data_loader)}], \"\n",
        "                  f\"Generator Loss: {g_loss.item():.4f}, Discriminator Loss: {d_loss.item():.4f}\")\n",
        "\n",
        "# Generate samples for visualization\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(16, latent_size).to(device)\n",
        "    fake_samples = generator(z).reshape(-1, 1, 28, 28)\n",
        "    fake_samples = (fake_samples + 1) / 2  # Rescale to [0, 1] for visualization\n",
        "\n",
        "# Visualize generated samples\n",
        "grid_img = vutils.make_grid(fake_samples, nrow=4, padding=2, normalize=True)\n",
        "plt.imshow(grid_img.permute(1, 2, 0))\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"Generated Samples - Epoch {epoch+1}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Game Theory and GANS\n",
        "\n",
        "Game theory is a mathematical framework that studies how individuals or entities interact strategically in situations where the outcome of their decisions depends not only on their own actions but also on the actions of others. It provides a powerful tool to analyze and predict the behavior and outcomes of strategic interactions.\n",
        "\n",
        "One of the fundamental concepts in game theory is the game itself, which consists of players, strategies, and payoffs. Players are the decision-makers in the game, and they choose from a set of strategies to determine their actions. The payoffs represent the outcomes or rewards associated with each combination of strategies chosen by the players.\n",
        "\n",
        "There are different types of games, such as cooperative games, non-cooperative games, simultaneous games, and sequential games. In cooperative games, players form coalitions and work together to achieve common goals. Non-cooperative games, on the other hand, involve players making decisions independently and without explicit communication or cooperation.\n",
        "\n",
        "To illustrate game theory, let's consider the classic example of the Prisoner's Dilemma. Two individuals are arrested for a crime, and they are held in separate cells. The prosecutor offers each prisoner a deal: if one stays silent (cooperates) and the other confesses (defects), the defector will receive a reduced sentence, while the cooperator will face a harsher penalty. If both prisoners confess, they both receive moderate sentences. If both stay silent, they both receive lighter sentences.\n",
        "\n",
        "In this game, the players (prisoners) have two strategies: cooperate (stay silent) or defect (confess). The payoffs could be represented by the length of their prison sentences. Each player's payoff depends on their own strategy as well as the strategy chosen by the other player. The game theory analysis reveals that, despite the potential for cooperation leading to a better outcome for both players, the dominant strategy for each player is to defect. This demonstrates the tension between individual rationality and collective welfare in strategic interactions.\n",
        "\n",
        "Now, let's connect game theory to Generative Adversarial Networks (GANs). GANs can be seen as a game between the generator and discriminator networks. The generator's goal is to produce synthetic data that resembles the real data, while the discriminator aims to distinguish between real and generated data. This adversarial game between the two networks creates a dynamic equilibrium, where the generator learns to generate increasingly realistic samples, and the discriminator becomes more skilled at distinguishing between real and fake data.\n",
        "\n",
        "In this game-theoretic setting, the generator and discriminator update their strategies (network parameters) iteratively based on the outcomes (classification accuracy) and the anticipated strategies of their opponents. The generator aims to minimize the discriminator's ability to differentiate between real and fake samples, while the discriminator aims to maximize its accuracy. This competitive process drives the training of GANs and leads to the generation of high-quality synthetic data.\n"
      ],
      "metadata": {
        "id": "23wRsYqyLWNH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9IBwcvvLAaIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conv Gans\n",
        "\n",
        "Generator:\n",
        "The generator in a GAN is like a skilled forger who tries to create realistic counterfeit artworks. It takes as input a random noise vector (latent space) and tries to generate data that resembles the real data. The generator uses a series of transformations and learned parameters to convert the random noise into meaningful output. Over time, the generator learns to produce data that becomes indistinguishable from the real data, fooling the discriminator.\n",
        "\n",
        "Discriminator:\n",
        "The discriminator in a GAN is like an expert art critic who is trained to differentiate between real artworks and the counterfeit ones created by the generator. Its role is to assess the authenticity of the generated data by distinguishing it from the real data. The discriminator is a binary classifier that receives input data and outputs a probability indicating whether the input is real or fake. It learns to become more accurate in identifying the generated data as the training progresses.\n",
        "\n",
        "Training Process:\n",
        "During the training process, the generator and discriminator engage in a competitive game. The generator aims to generate data that the discriminator cannot distinguish from real data, while the discriminator aims to correctly classify the real and generated data. As the generator gets better at creating realistic data, the discriminator is continuously challenged to improve its ability to differentiate between real and fake data.\n",
        "\n",
        "The interaction between the generator and discriminator creates a feedback loop. The generator learns to generate more realistic data by receiving feedback from the discriminator, which helps it improve its output. Similarly, the discriminator learns to become more accurate in distinguishing between real and fake data by continuously facing more challenging generated data from the generator.\n",
        "\n",
        "Through this adversarial process, the generator and discriminator improve iteratively, and ideally, the generator learns to generate data that is indistinguishable from the real data, leading to the creation of high-quality synthetic data.\n",
        "\n",
        "Overall, the generator and discriminator work together in a GAN to achieve the ultimate goal of generating realistic data that resembles the real-world distribution.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "joTXHRZTJg5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Hyperparameters\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "lr = 0.0002\n",
        "batch_size = 128\n",
        "num_epochs = 100\n",
        "\n",
        "# MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "mnist_data = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "data_loader = DataLoader(dataset=mnist_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=100, img_channels=1):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(latent_dim, 256, kernel_size=7, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, img_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.latent_dim, 1, 1)\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_channels=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(img_channels, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 1, kernel_size=7, stride=1, padding=0),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Optimizers\n",
        "gen_optimizer = optim.Adam(generator.parameters(), lr=lr)\n",
        "disc_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Training loop\n",
        "total_step = len(data_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(data_loader):\n",
        "        images = images.to(device)\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        # Create labels for real and fake data\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # === Train Discriminator ===\n",
        "        disc_optimizer.zero_grad()\n",
        "\n",
        "        # Compute discriminator loss on real data\n",
        "        real_output = discriminator(images)\n",
        "        real_labels = torch.ones_like(real_output)  # Reshape real_labels\n",
        "        real_loss = criterion(real_output, real_labels)\n",
        "\n",
        "        # Generate fake data\n",
        "        z = torch.randn(batch_size, 100, 1, 1).to(device)\n",
        "        fake_images = generator(z)\n",
        "\n",
        "        # Compute discriminator loss on fake data\n",
        "        fake_output = discriminator(fake_images.detach())\n",
        "        fake_labels = torch.zeros_like(fake_output)  # Reshape fake_labels\n",
        "        fake_loss = criterion(fake_output, fake_labels)\n",
        "\n",
        "        # Compute total discriminator loss and backpropagate\n",
        "        disc_loss = real_loss + fake_loss\n",
        "        disc_loss.backward()\n",
        "        disc_optimizer.step()\n",
        "\n",
        "        # === Train Generator ===\n",
        "        gen_optimizer.zero_grad()\n",
        "\n",
        "        # Generate fake data\n",
        "        z = torch.randn(batch_size, 100, 1, 1).to(device)\n",
        "        fake_images = generator(z)\n",
        "\n",
        "        # Compute generator loss\n",
        "        outputs = discriminator(fake_images)\n",
        "        gen_loss = criterion(outputs, real_labels)\n",
        "\n",
        "        # Backpropagate and update generator weights\n",
        "        gen_loss.backward()\n",
        "        gen_optimizer.step()\n",
        "\n",
        "        # Print training progress\n",
        "        if (i + 1) % 200 == 0:\n",
        "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_step}], \"\n",
        "                  f\"Generator Loss: {gen_loss.item():.4f}, Discriminator Loss: {disc_loss.item():.4f}\")\n",
        "\n",
        "# Generate and display a sample of generated images\n",
        "num_samples = 25\n",
        "z = torch.randn(num_samples, 100, 1, 1).to(device)\n",
        "generated_images = generator(z).detach().cpu()\n",
        "\n",
        "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(10, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(num_samples):\n",
        "    img = generated_images[i].squeeze()\n",
        "    axes[i].imshow(img, cmap='gray')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a2XyW7u9Jirp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZHMjgyUvJmPB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}