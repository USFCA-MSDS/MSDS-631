{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# What is Gradient Decent ?\n",
        "\n",
        "\n",
        "Gradient descent is a powerful optimization algorithm that allows models to learn from data by iteratively adjusting their parameters to minimize the loss. It is widely used in training machine learning models and forms the basis for many advanced optimization techniques used in deep learning.\n",
        "\n",
        "\n",
        "Here's an intuition of how gradient descent works:\n",
        "\n",
        "* Imagine you're standing on a mountain and your goal is to reach the lowest point in the surrounding area. You're blindfolded, so you can't see the entire landscape. You can only feel the slope beneath your feet.\n",
        "\n",
        "* To find the lowest point, you take small steps in the direction that feels steepest downhill. With each step, you evaluate the slope at your current position.\n",
        "\n",
        "* The slope represents the derivative or gradient of the landscape at that point. If the slope is steep, it means you're far from the bottom, and you need to take bigger steps. If the slope is shallow, it means you're closer to the bottom, and you should take smaller steps.\n",
        "\n",
        "* You repeat this process, updating your position and evaluating the slope at each step. Gradually, you move closer to the lowest point.\n",
        "\n",
        "In the context of optimization in machine learning:\n",
        "\n",
        "* The landscape represents the space of possible parameter values of a model, and the lowest point corresponds to the optimal parameter values that minimize the loss function.\n",
        "* The slope or gradient represents the derivative of the loss function with respect to the model's parameters. It tells us the direction and magnitude of the steepest increase or decrease in the loss.\n",
        "* Taking steps in the direction opposite to the gradient allows us to descend towards the minimum of the loss function.\n",
        "* The size of the steps is controlled by the learning rate, which determines how far to move in each iteration. A larger learning rate leads to bigger steps, but it may overshoot the minimum. A smaller learning rate takes smaller steps, but it may converge slowly.\n",
        "* The process of updating the parameters based on the gradient is repeated iteratively until a stopping criterion is met, such as reaching a maximum number of iterations or the loss function converging to a desired threshold."
      ],
      "metadata": {
        "id": "9nbAiCyLRpFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient decent for a dense layer\n",
        "\n",
        "1. Initialize the weights and biases of the model, $\\mathbf{W}$ and $\\mathbf{b}$, randomly.\n",
        "\n",
        "2. Feed the input $\\mathbf{X}$ through the model to get the predicted output $\\hat{\\mathbf{y}}$:\n",
        "\n",
        "$$\\hat{\\mathbf{y}} = \\sigma(\\mathbf{XW}+\\mathbf{b})$$\n",
        "\n",
        "where $\\sigma$ is the activation function.\n",
        "\n",
        "3. Compute the loss between the predicted output and the true output $\\mathbf{y}$ using a loss function $L$:\n",
        "\n",
        "$$L = -\\frac{1}{N}\\sum_{i=1}^N[y_i\\log(\\hat{y_i}) + (1-y_i)\\log(1-\\hat{y_i})]$$\n",
        "\n",
        "where $N$ is the number of training samples, $y_i$ is the true label of the $i$-th sample, and $\\hat{y_i}$ is the predicted label.\n",
        "\n",
        "4. Compute the gradient of the loss with respect to the model parameters $\\nabla_{\\mathbf{W}}, \\nabla_{\\mathbf{b}}$ using backpropagation.\n",
        "\n",
        "5. Update the model parameters using the gradients and an optimization algorithm, such as stochastic gradient descent (SGD):\n",
        "\n",
        "$$\\mathbf{W} \\leftarrow \\mathbf{W} - \\alpha\\nabla_{\\mathbf{W}} L$$\n",
        "\n",
        "$$\\mathbf{b} \\leftarrow \\mathbf{b} - \\alpha\\nabla_{\\mathbf{b}} L$$\n",
        "\n",
        "where $\\alpha$ is the learning rate.\n",
        "\n",
        "6. Repeat steps 2-5 for a certain number of epochs or until convergence is reached.\n",
        "\n",
        "The goal of training is to find the weights and biases that minimize the loss function on the training set, so that the network can generalize well to new inputs."
      ],
      "metadata": {
        "id": "6evSVXrJGqx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Iv1zN_ETRnyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remark \n",
        "\n",
        "\n",
        "In the context of training a neural network, the gradient refers to the vector of partial derivatives of the loss function with respect to the weights of the network. The gradient is a way to measure how the loss function changes as the weights of the network are adjusted during training.\n",
        "\n",
        "In the notation used in the training steps above, $\\nabla_{\\theta}L$ represents the gradient of the loss function $L$ with respect to the weights of the network, denoted by $\\theta$. This gradient is computed using backpropagation, which involves computing the partial derivatives of the loss function with respect to each weight in the network. The optimizer then uses the gradient to adjust the weights of the network in the direction that minimizes the loss.\n",
        "\n",
        "\n",
        "\n",
        "In more details :   \n",
        "\n",
        "$$\\mathbf{w} = \\mathbf{w} - \\eta \\cdot \\nabla_{\\mathbf{w}} L$$\n",
        "\n",
        "- $ \\nabla_{\\mathbf{w}} L$ represents the gradient of the cost function $J$ with respect to the weights $\\mathbf{w}$.\n",
        "- The gradient is a vector of partial derivatives, which tells us how much the cost function changes in response to small changes in each weight.\n",
        "- For example, if we have a neural network with weights $\\mathbf{w} = [w_1, w_2, w_3]$, then the gradient might look something like $ \\nabla_{\\mathbf{w}} L  = [\\frac{\\partial L}{\\partial w_1}, \\frac{\\partial L}{\\partial w_2}, \\frac{\\partial L}{\\partial w_3}]$.\n",
        "- Each partial derivative in the gradient tells us how much the cost function will change if we increase or decrease that weight slightly. For example, $\\frac{\\partial L}{\\partial w_1}$ tells us how much the cost function will change if we increase or decrease $w_1$ by a tiny amount, while keeping all other weights constant.\n",
        "- The learning rate $\\eta$ controls how big of a step we take in the direction of the gradient. If the learning rate is too small, we'll take tiny steps and the optimization will be very slow. If the learning rate is too large, we'll take huge steps and risk overshooting the optimal weights.\n",
        "- So the update equation $\\mathbf{w} = \\mathbf{w} - \\eta \\cdot \\nabla_{\\mathbf{w}} L $ tells us to update the weights by subtracting a scaled version of the gradient. This moves the weights in the direction of steepest descent of the cost function, which hopefully takes us closer to the optimal weights."
      ],
      "metadata": {
        "id": "FNYxmzdYHOtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6M8UMUS_HK4Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}