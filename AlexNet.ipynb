{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "indN9P763g-E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objectives\n",
        "* train a conv net on the MNIST dataset \n",
        "* Introduce the main building blocks pooling and con layers"
      ],
      "metadata": {
        "id": "NzqGeQ3W8c0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "kKDsyvmH_3Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.Conv2d\n",
        "\n",
        "\n",
        "* in_channels (int) – Number of channels in the input image\n",
        "\n",
        "\n",
        "* out_channels (int) – Number of channels produced by the convolution\n",
        "\n",
        "* kernel_size (int or tuple) – Size of the convolving kernel\n",
        "\n",
        "* stride (int or tuple, optional) – Stride of the convolution. Default: 1\n",
        "\n",
        "* padding (int, tuple or str, optional) – Padding added to all four sides of the input. Default: 0\n",
        "\n",
        "* padding_mode (str, optional) – 'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'\n",
        "\n",
        "* dilation (int or tuple, optional) – Spacing between kernel elements. Default: 1\n",
        "\n",
        "* groups (int, optional) – Number of blocked connections from input channels to output channels. Default: 1\n",
        "\n",
        "* bias (bool, optional) – If True, adds a learnable bias to the output. Default: True"
      ],
      "metadata": {
        "id": "8UvXFfVP_6V3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For images in Pytorch the convention to store data is always : ( #batch_size , # number_of_channels ​, #heigh_of_image ,#width_of_image) \n",
        "\n",
        "\n",
        "# lets create a random tensor that represents a dataset\n",
        "\n",
        "in_channels_ = 16\n",
        "\n",
        "\n",
        "input = torch.randn(10, in_channels_, 100, 100)\n",
        "\n",
        "# the way to read the above : we have 10 images, each one of them is a tensor of width and height = 100 and has 16 channels.\n",
        "\n",
        "\n",
        "m = nn.Conv2d(in_channels = in_channels_, out_channels=  33, kernel_size=(3,3))\n",
        "\n",
        "\n",
        "output = m(input)\n",
        "\n",
        "\n",
        "print(output.shape)\n",
        "\n",
        "# output has the same shape: there are 10 images output, each one of them is a tensor of width and height 98 and has 33 channels.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKYT6e_E-fC-",
        "outputId": "292c0636-f8a7-436a-df5b-c43e16d6f8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 33, 98, 98])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe that the kernel size affects the size of the output: the larger the kernel size the smaller the width and height of the tensor"
      ],
      "metadata": {
        "id": "GuYaR8I8DPp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels_ = 16\n",
        "\n",
        "input = torch.randn(10, in_channels_, 100, 100)\n",
        "\n",
        "# the way to read the above : we have 10 images, each one of them is a tensor of width and height = 100 and has 16 channels.\n",
        "\n",
        "\n",
        "m = nn.Conv2d(in_channels = in_channels_, out_channels=  33, kernel_size=(5,5)) \n",
        "\n",
        "\n",
        "output = m(input)\n",
        "\n",
        "\n",
        "print(output.shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj4q_g5cDWwv",
        "outputId": "ea73a9a1-0454-4379-b06c-f1354d881ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 33, 96, 96])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding \"pads\" parts to the border of the image to prevent the size from being changed "
      ],
      "metadata": {
        "id": "j50dRWdrIKyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels_ = 16\n",
        "\n",
        "input = torch.randn(10, in_channels_, 100, 100)\n",
        "\n",
        "# the way to read the above : we have 10 images, each one of them is a tensor of width and height = 100 and has 16 channels.\n",
        "\n",
        "\n",
        "m = nn.Conv2d(in_channels = in_channels_, out_channels=  33, kernel_size=(5,5),padding=2) # pad twp pixels at each side\n",
        "\n",
        "\n",
        "output = m(input)\n",
        "\n",
        "\n",
        "print(output.shape) # size is the same as input!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmwbD8rBIV7x",
        "outputId": "df2a683d-7473-4701-bf63-ddfb8940fac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 33, 100, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pooling\n"
      ],
      "metadata": {
        "id": "qEalek42QfBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pooling is a technique commonly used in deep learning for down-sampling feature maps. It helps reduce the spatial dimensions of the feature maps, while retaining the most important information.\n",
        "\n",
        "In PyTorch, the Pool2d module performs 2D max pooling operation on a given input tensor. The size of the pooling kernel and stride can be specified as arguments.\n",
        "\n",
        "Here's an example of using Pool2d with a size change:"
      ],
      "metadata": {
        "id": "0GU25NpSXjv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define a 2D convolutional neural network layer\n",
        "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
        "\n",
        "# Define a 2D max pooling layer with size change\n",
        "pool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "# Define an example input tensor\n",
        "x = torch.randn(1, 3, 32, 32)  # batch_size=1, channels=3, height=32, width=32\n",
        "\n",
        "# Pass the input tensor through the convolutional layer\n",
        "conv_out = conv_layer(x)\n",
        "\n",
        "\n",
        "print(\"size after conv layer\",conv_out.shape )\n",
        "\n",
        "# Pass the convolutional output through the pooling layer\n",
        "pooled_out = pool_layer(conv_out)\n",
        "\n",
        "# The size of the output tensor after the pooling layer is reduced by a factor of 2 in both dimensions\n",
        "print(\"size after pooling layer\",pooled_out.size())  # Output: torch.Size([1, 16, 15, 15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbzCfvDKXlKl",
        "outputId": "d91b95d9-0a41-46a8-af40-1bf45b023073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size after conv layer torch.Size([1, 16, 30, 30])\n",
            "size after pooling layer torch.Size([1, 16, 15, 15])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example above, we define a convolutional layer with 3 input channels, 16 output channels, and a kernel size of 3. We then define a max pooling layer with a kernel size of 2 and stride of 2, which reduces the size of the feature maps by a factor of 2 in both dimensions. Finally, we pass an example input tensor through the convolutional layer, followed by the pooling layer, and print the size of the output tensor.\n",
        "\n",
        "# More Pooling examples\n"
      ],
      "metadata": {
        "id": "V-fgVZa1YORE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pool of square window\n",
        "m = nn.MaxPool2d((3, 3), stride=(1, 1),padding=1) \n",
        "input = torch.randn(1, 16, 100, 100)\n",
        "output = m(input)\n",
        "output.shape # observe the output dimension W and H have the same size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR37Ac9JQgwT",
        "outputId": "d369362c-a1ce-4d15-c74b-55648a157164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 100, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we are creating a 2D max pooling layer using nn.MaxPool2d() from the PyTorch nn module. The pooling layer is specified to use a square window of size (3, 3) and a stride of (1, 1). Additionally, the padding is set to 1 on both sides of the input tensor.\n",
        "\n",
        "Next, we create an example input tensor with a batch size of 1, 16 input channels, and a spatial dimension of 100 x 100.\n",
        "\n",
        "We then pass this input tensor through the pooling layer by calling m(input). The max pooling operation will compute the maximum value within each (3, 3) window of the input tensor, sliding the window over the input tensor with a stride of (1, 1). The padding of 1 on both sides ensures that the output tensor has the same spatial dimensions as the input tensor.\n",
        "\n",
        "Finally, we print the shape of the output tensor using output.shape. Since the pooling layer has reduced the spatial dimensions of the input tensor by (3-1) + 2*1 = 3 in both dimensions due to the padding, and since we are using a stride of (1, 1), the output tensor has the same spatial dimensions as the input tensor: 100 x 100. However, the number of output channels has been reduced to 16 since we are using a max pooling layer. So the output shape is (1, 16, 100, 100).\n"
      ],
      "metadata": {
        "id": "HBaof3UkYbgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pool of square window\n",
        "m = nn.MaxPool2d((3, 3), stride=(2, 2),padding=1) \n",
        "input = torch.randn(1, 16, 100, 100)\n",
        "output = m(input)\n",
        "output.shape  # observe the output dimension W and H have half of the size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1DUwlbtXCx9",
        "outputId": "4bef3d1d-f8bf-4f36-c048-9fe05ebe45a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 50, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How do you compute the size\n",
        "\n",
        "The formula for computing the output size of a 2D pooling operation given an input tensor of size (N, C, H, W) and pooling window of size (kH, kW) with stride (sH, sW) and padding (pH, pW) can be given as:\n",
        "\n",
        "\n",
        "output_height = floor((H + 2*pH - kH) / sH) + 1\n",
        "output_width = floor((W + 2*pW - kW) / sW) + 1\n",
        "\n",
        "\n",
        "\n",
        "Here, floor() is the floor function that rounds down to the nearest integer. The term (H + 2*pH - kH) computes the spatial size of the output tensor after applying the pooling operation along the height dimension. Similarly, (W + 2*pW - kW) computes the spatial size of the output tensor after applying the pooling operation along the width dimension. Finally, we add 1 to the result of each division to obtain the output size.\n",
        "\n",
        "Note that if the pooling operation does not result in an integer output size, then the input size needs to be padded with additional elements to ensure that the output size is an integer. This is often done by setting the padding values (pH, pW) accordingly.\n",
        "\n",
        "It's important to keep in mind that different pooling operations may have different output sizes, even when applied to the same input tensor with the same pooling window, stride, and padding. For example, a max pooling operation only selects the maximum value within the pooling window, while an average pooling operation computes the average of all the values within the pooling window. This can lead to different output sizes for different pooling operations."
      ],
      "metadata": {
        "id": "1OG-3LERY7u8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of computing the size in a pooling \n",
        "\n",
        "Suppose we have an input tensor x of size (1, 3, 32, 32) and a max pooling layer with a pooling window of size (2, 2), a stride of (2, 2), and (1,1) padding. To compute the output size, we can use the formula:\n",
        "\n",
        "\n",
        "\n",
        "**output_height = floor((H +2pH - kH) / sH) + 1**\n",
        "\n",
        "**output_width = floor((W  +2pH - kW) / sW) + 1 **\n",
        "\n",
        "\n",
        "\n",
        "where H and W are the height and width of the input tensor, and kH and kW are the height and width of the pooling window. In this case, we have H = 32, W = 32, kH = 2, kW = 2, sH = 2, and sW = 2, so we can substitute these values into the formula:\n",
        "\n",
        "\n",
        "**output_height = floor((32 +2 - 2) / 2) + 1 = 17**\n",
        "\n",
        "**output_width = floor((32 +2 - 2) / 2) + 1 = 17**\n",
        "\n",
        "\n",
        "\n",
        "Therefore, the output size of the max pooling operation is (1, 3, 17, 17).\n",
        "\n",
        "## Things to do\n",
        "\n",
        "As an exercise, you could try computing the output size of a max pooling operation with a different set of parameters. For example, given an input tensor x of size (1, 3, 28, 28) and a max pooling layer with a pooling window of size (3, 3), a stride of (2, 2), and padding of (1, 1), you could try to compute the output size using the formula provided earlier. This exercise will help you better understand how the output size of a pooling operation is affected by different parameters."
      ],
      "metadata": {
        "id": "U0YTArWLZ3L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define an example input tensor\n",
        "x = torch.randn(1, 3, 32, 32)  # batch_size=1, channels=3, height=32, width=32\n",
        "\n",
        "\n",
        "# Define a 2D max pooling layer with size change\n",
        "pool_layer = nn.MaxPool2d(kernel_size=2, stride=2,padding=1)\n",
        "\n",
        "# Pass the convolutional output through the pooling layer\n",
        "pooled_out = pool_layer(x)\n",
        "\n",
        "print(\"size after pooling layer\",pooled_out.size())  # Output: torch.Size([1, 16, 15, 15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz14rG_KbIId",
        "outputId": "80bef95a-8f89-46f5-afef-b6d020669cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size after pooling layer torch.Size([1, 3, 17, 17])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a network similar to AlexNet"
      ],
      "metadata": {
        "id": "tWfV17HZ_qQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the libraries we will need :\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tGue2KEy8yZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the MNIST dataset\n",
        "\n",
        "The MNIST dataset is a large database of handwritten digits used for training and testing various image processing systems. It consists of 70,000 grayscale images of size 28 x 28 pixels, each representing a handwritten digit between 0 and 9. The dataset is divided into a training set of 60,000 images and a test set of 10,000 images, which are commonly used to evaluate the performance of machine learning models for image classification tasks. The MNIST dataset has been widely used in research and has become a standard benchmark for image classification algorithms."
      ],
      "metadata": {
        "id": "1DghIhzZ77bS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
        "    batch_size=1000)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C3_Gg2t4FJL",
        "outputId": "c5c001d3-9aaf-46a3-f338-09d9d6826f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 92895615.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 21159073.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 26337824.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 10292019.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NcVLEiNr8Nh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CDek-Ocg7gBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MnistModel, self).__init__()\n",
        "        # input is 28x28\n",
        "        # padding=2 for same padding\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n",
        "        # feature map size is 14*14 by pooling\n",
        "        # padding=2 for same padding\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n",
        "        # feature map size is 7*7 by pooling\n",
        "        self.fc1 = nn.Linear(64*7*7, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x) \n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = x.view(-1, 64*7*7)   # reshape Variable\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)\n",
        "    \n"
      ],
      "metadata": {
        "id": "PX_a9rBX7gnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remark : \n",
        "In general the constructor of an nn.Module contains *trainable* layers which means they have parameters that will be optimized during the backprob algorithm. Observe that in the previous example we declared **nn.Conv2d** inside the init function because it has a trainable component but we did not delacare  **max_pool2d, F.relu, F.dropout** inside the same constructor.\n",
        "\n",
        "\n",
        "In a general sense, we can consider the torch.nn layers as having trainable parameters, while torch.nn.functional functions are solely functional in nature. The forward() method defines how we compute the output using the provided **layers and functions**. It is acceptable to include tensor printing within the forward pass for convenient debugging, especially when working with intricate models. It's important to note that the forward pass can utilize various elements such as member variables, the data itself, or even multiple arguments to determine the execution computation."
      ],
      "metadata": {
        "id": "wh29r2C3yej4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prep for training\n",
        "\n",
        "With the imports in place we can go ahead and prepare the data we'll be using. But before that we'll define the hyperparameters we'll be using for the experiment. Here the number of epochs defines how many times we'll loop over the complete training dataset, while learning_rate and momentum are hyperparameters for the optimizer we'll be using later on.\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3raN2klgz6dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 3\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "learning_rate = 0.01\n",
        "momentum = 0.5\n",
        "log_interval = 10\n",
        "\n",
        "random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXu65xxO0Aiv",
        "outputId": "9a2cf872-4fb7-4bf1-f3d8-21df98e03ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f46281f4c10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cifeLGjw5Os3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some terms  \n",
        "\n",
        "**Iteration**: each time you update model weights\n",
        "\n",
        "**Batch**: a subset of data used in an iteration\n",
        "\n",
        "**Epoch**: the number of iterations to look at all n\n",
        " observations (people sometimes also say a “full pass through the dataset”)\n"
      ],
      "metadata": {
        "id": "4hCHat0p5PtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = MnistModel()\n",
        "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
        "                      momentum=momentum)"
      ],
      "metadata": {
        "id": "Bp_C4K1CzAOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The training loop\n",
        "\n",
        "\n",
        "\n",
        "Let's proceed to construct our training loop. Initially, we ensure that our network is in training mode. Then, for each epoch, we iterate through all the training data. The DataLoader takes care of loading the individual batches. Firstly, we manually reset the gradients to zero using optimizer.zero_grad() because PyTorch accumulates gradients by default. Next, we obtain the output of our network (forward pass) and calculate the negative log-likelihood loss between the output and the ground truth label. By invoking the backward() function, we gather a fresh set of gradients, which we subsequently propagate back into each parameter of the network using optimizer.step(). If you're interested in gaining a more comprehensive understanding of PyTorch's automatic gradient system, I highly recommend referring to the official documentation for autograd."
      ],
      "metadata": {
        "id": "mWhsBi4I0UkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will monitor the progress by printing out information during the training process. To generate a smooth training curve later on, we create two lists to store the training and testing losses. For the x-axis of the curve, we aim to display the number of training examples the network has processed during training.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B4XoSd171g-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
      ],
      "metadata": {
        "id": "hiWJGtfN0h0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(epoch):\n",
        "  network.train()  # Set the network to training mode\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):  # Iterate over batches in the training data\n",
        "    optimizer.zero_grad()  # Reset gradients to zero\n",
        "    output = network(data)  # Forward pass to obtain network output\n",
        "    loss = F.nll_loss(output, target)  # Compute the negative log-likelihood loss\n",
        "    loss.backward()  # Backpropagate to calculate gradients\n",
        "    optimizer.step()  # Update network parameters using optimizer\n",
        "    if batch_idx % log_interval == 0:  # Print and log training progress at specified intervals\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "        100. * batch_idx / len(train_loader), loss.item()))\n",
        "      train_losses.append(loss.item())  # Log the training loss\n",
        "      train_counter.append(\n",
        "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))  # Log the training step count\n",
        "      "
      ],
      "metadata": {
        "id": "_hklFvsr0iD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  network.eval()  # Set the network to evaluation mode\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:  # Iterate over batches in the test data\n",
        "      output = network(data)  # Forward pass to obtain network output\n",
        "      test_loss += F.nll_loss(output, target, size_average=False).item()  # Compute the test loss\n",
        "      pred = output.data.max(1, keepdim=True)[1]  # Get the predicted labels\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()  # Count the number of correct predictions\n",
        "  test_loss /= len(test_loader.dataset)  # Compute the average test loss\n",
        "  test_losses.append(test_loss)  # Log the test loss\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))  # Print the average test loss and accuracy\n"
      ],
      "metadata": {
        "id": "zuWTtC8L0tf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test()\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7_GlUsV1F-P",
        "outputId": "87dde5f2-68a3-4ace-84f1-90cb436397ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-266f9f53284e>:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.3000, Accuracy: 1131/10000 (11%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.295619\n",
            "Train Epoch: 1 [500/60000 (1%)]\tLoss: 2.285803\n",
            "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.287543\n",
            "Train Epoch: 1 [1500/60000 (2%)]\tLoss: 2.258172\n",
            "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.224676\n",
            "Train Epoch: 1 [2500/60000 (4%)]\tLoss: 2.202688\n",
            "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.197871\n",
            "Train Epoch: 1 [3500/60000 (6%)]\tLoss: 2.140297\n",
            "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.095403\n",
            "Train Epoch: 1 [4500/60000 (8%)]\tLoss: 2.005866\n",
            "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 1.834223\n",
            "Train Epoch: 1 [5500/60000 (9%)]\tLoss: 1.652802\n",
            "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.378147\n",
            "Train Epoch: 1 [6500/60000 (11%)]\tLoss: 1.124001\n",
            "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.982802\n",
            "Train Epoch: 1 [7500/60000 (12%)]\tLoss: 0.987219\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.781626\n",
            "Train Epoch: 1 [8500/60000 (14%)]\tLoss: 0.729633\n",
            "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.731051\n",
            "Train Epoch: 1 [9500/60000 (16%)]\tLoss: 0.709797\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.705079\n",
            "Train Epoch: 1 [10500/60000 (18%)]\tLoss: 0.540323\n",
            "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.798053\n",
            "Train Epoch: 1 [11500/60000 (19%)]\tLoss: 0.861721\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.487398\n",
            "Train Epoch: 1 [12500/60000 (21%)]\tLoss: 0.409128\n",
            "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.479242\n",
            "Train Epoch: 1 [13500/60000 (22%)]\tLoss: 0.604425\n",
            "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.738487\n",
            "Train Epoch: 1 [14500/60000 (24%)]\tLoss: 0.323492\n",
            "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.548333\n",
            "Train Epoch: 1 [15500/60000 (26%)]\tLoss: 0.600853\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.405861\n",
            "Train Epoch: 1 [16500/60000 (28%)]\tLoss: 0.712054\n",
            "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.538748\n",
            "Train Epoch: 1 [17500/60000 (29%)]\tLoss: 0.398829\n",
            "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.352690\n",
            "Train Epoch: 1 [18500/60000 (31%)]\tLoss: 0.364524\n",
            "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.322529\n",
            "Train Epoch: 1 [19500/60000 (32%)]\tLoss: 0.503579\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.365465\n",
            "Train Epoch: 1 [20500/60000 (34%)]\tLoss: 0.339147\n",
            "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.629723\n",
            "Train Epoch: 1 [21500/60000 (36%)]\tLoss: 0.567616\n",
            "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.617208\n",
            "Train Epoch: 1 [22500/60000 (38%)]\tLoss: 0.517310\n",
            "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.213992\n",
            "Train Epoch: 1 [23500/60000 (39%)]\tLoss: 0.326176\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.314135\n",
            "Train Epoch: 1 [24500/60000 (41%)]\tLoss: 0.256589\n",
            "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.352030\n",
            "Train Epoch: 1 [25500/60000 (42%)]\tLoss: 0.380715\n",
            "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.448031\n",
            "Train Epoch: 1 [26500/60000 (44%)]\tLoss: 0.101292\n",
            "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.160490\n",
            "Train Epoch: 1 [27500/60000 (46%)]\tLoss: 0.347019\n",
            "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.145011\n",
            "Train Epoch: 1 [28500/60000 (48%)]\tLoss: 0.138248\n",
            "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.290421\n",
            "Train Epoch: 1 [29500/60000 (49%)]\tLoss: 0.570659\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.273108\n",
            "Train Epoch: 1 [30500/60000 (51%)]\tLoss: 0.178293\n",
            "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.480969\n",
            "Train Epoch: 1 [31500/60000 (52%)]\tLoss: 0.174653\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.377201\n",
            "Train Epoch: 1 [32500/60000 (54%)]\tLoss: 0.185968\n",
            "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.211389\n",
            "Train Epoch: 1 [33500/60000 (56%)]\tLoss: 0.253154\n",
            "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.233316\n",
            "Train Epoch: 1 [34500/60000 (58%)]\tLoss: 0.365480\n",
            "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.248501\n",
            "Train Epoch: 1 [35500/60000 (59%)]\tLoss: 0.128509\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.138663\n",
            "Train Epoch: 1 [36500/60000 (61%)]\tLoss: 0.201584\n",
            "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.290483\n",
            "Train Epoch: 1 [37500/60000 (62%)]\tLoss: 0.268822\n",
            "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.132368\n",
            "Train Epoch: 1 [38500/60000 (64%)]\tLoss: 0.261780\n",
            "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.412637\n",
            "Train Epoch: 1 [39500/60000 (66%)]\tLoss: 0.287882\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.417344\n",
            "Train Epoch: 1 [40500/60000 (68%)]\tLoss: 0.286707\n",
            "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.235869\n",
            "Train Epoch: 1 [41500/60000 (69%)]\tLoss: 0.316359\n",
            "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.223910\n",
            "Train Epoch: 1 [42500/60000 (71%)]\tLoss: 0.289269\n",
            "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.071768\n",
            "Train Epoch: 1 [43500/60000 (72%)]\tLoss: 0.178606\n",
            "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.249363\n",
            "Train Epoch: 1 [44500/60000 (74%)]\tLoss: 0.316863\n",
            "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.214005\n",
            "Train Epoch: 1 [45500/60000 (76%)]\tLoss: 0.311864\n",
            "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.380919\n",
            "Train Epoch: 1 [46500/60000 (78%)]\tLoss: 0.156883\n",
            "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.238712\n",
            "Train Epoch: 1 [47500/60000 (79%)]\tLoss: 0.255665\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.117729\n",
            "Train Epoch: 1 [48500/60000 (81%)]\tLoss: 0.151559\n",
            "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.164071\n",
            "Train Epoch: 1 [49500/60000 (82%)]\tLoss: 0.200702\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.227751\n",
            "Train Epoch: 1 [50500/60000 (84%)]\tLoss: 0.119041\n",
            "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.209530\n",
            "Train Epoch: 1 [51500/60000 (86%)]\tLoss: 0.158199\n",
            "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.083901\n",
            "Train Epoch: 1 [52500/60000 (88%)]\tLoss: 0.181049\n",
            "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.209815\n",
            "Train Epoch: 1 [53500/60000 (89%)]\tLoss: 0.065894\n",
            "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.292722\n",
            "Train Epoch: 1 [54500/60000 (91%)]\tLoss: 0.086332\n",
            "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.181174\n",
            "Train Epoch: 1 [55500/60000 (92%)]\tLoss: 0.243803\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.118417\n",
            "Train Epoch: 1 [56500/60000 (94%)]\tLoss: 0.077469\n",
            "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.152924\n",
            "Train Epoch: 1 [57500/60000 (96%)]\tLoss: 0.312839\n",
            "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.166770\n",
            "Train Epoch: 1 [58500/60000 (98%)]\tLoss: 0.144062\n",
            "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.457551\n",
            "Train Epoch: 1 [59500/60000 (99%)]\tLoss: 0.140436\n",
            "\n",
            "Test set: Avg. loss: 0.1501, Accuracy: 9538/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.246413\n",
            "Train Epoch: 2 [500/60000 (1%)]\tLoss: 0.091517\n",
            "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.088392\n",
            "Train Epoch: 2 [1500/60000 (2%)]\tLoss: 0.085602\n",
            "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.210615\n",
            "Train Epoch: 2 [2500/60000 (4%)]\tLoss: 0.175042\n",
            "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.062895\n",
            "Train Epoch: 2 [3500/60000 (6%)]\tLoss: 0.299228\n",
            "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.107620\n",
            "Train Epoch: 2 [4500/60000 (8%)]\tLoss: 0.086011\n",
            "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.199494\n",
            "Train Epoch: 2 [5500/60000 (9%)]\tLoss: 0.351181\n",
            "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.216477\n",
            "Train Epoch: 2 [6500/60000 (11%)]\tLoss: 0.385975\n",
            "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.251417\n",
            "Train Epoch: 2 [7500/60000 (12%)]\tLoss: 0.190803\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.165985\n",
            "Train Epoch: 2 [8500/60000 (14%)]\tLoss: 0.167239\n",
            "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.115111\n",
            "Train Epoch: 2 [9500/60000 (16%)]\tLoss: 0.133170\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.316691\n",
            "Train Epoch: 2 [10500/60000 (18%)]\tLoss: 0.072222\n",
            "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.284133\n",
            "Train Epoch: 2 [11500/60000 (19%)]\tLoss: 0.168169\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.048163\n",
            "Train Epoch: 2 [12500/60000 (21%)]\tLoss: 0.063736\n",
            "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.081180\n",
            "Train Epoch: 2 [13500/60000 (22%)]\tLoss: 0.201867\n",
            "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.118579\n",
            "Train Epoch: 2 [14500/60000 (24%)]\tLoss: 0.160812\n",
            "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.122612\n",
            "Train Epoch: 2 [15500/60000 (26%)]\tLoss: 0.282611\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.109093\n",
            "Train Epoch: 2 [16500/60000 (28%)]\tLoss: 0.191945\n",
            "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.106480\n",
            "Train Epoch: 2 [17500/60000 (29%)]\tLoss: 0.230538\n",
            "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.289543\n",
            "Train Epoch: 2 [18500/60000 (31%)]\tLoss: 0.249564\n",
            "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.036746\n",
            "Train Epoch: 2 [19500/60000 (32%)]\tLoss: 0.330522\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.168152\n",
            "Train Epoch: 2 [20500/60000 (34%)]\tLoss: 0.202013\n",
            "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.091633\n",
            "Train Epoch: 2 [21500/60000 (36%)]\tLoss: 0.059400\n",
            "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.128610\n",
            "Train Epoch: 2 [22500/60000 (38%)]\tLoss: 0.174987\n",
            "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.133427\n",
            "Train Epoch: 2 [23500/60000 (39%)]\tLoss: 0.050437\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.149502\n",
            "Train Epoch: 2 [24500/60000 (41%)]\tLoss: 0.023285\n",
            "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.091976\n",
            "Train Epoch: 2 [25500/60000 (42%)]\tLoss: 0.058736\n",
            "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.216361\n",
            "Train Epoch: 2 [26500/60000 (44%)]\tLoss: 0.212238\n",
            "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.111150\n",
            "Train Epoch: 2 [27500/60000 (46%)]\tLoss: 0.062748\n",
            "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.099851\n",
            "Train Epoch: 2 [28500/60000 (48%)]\tLoss: 0.099173\n",
            "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.049508\n",
            "Train Epoch: 2 [29500/60000 (49%)]\tLoss: 0.100297\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.038378\n",
            "Train Epoch: 2 [30500/60000 (51%)]\tLoss: 0.058134\n",
            "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.110271\n",
            "Train Epoch: 2 [31500/60000 (52%)]\tLoss: 0.019848\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.097952\n",
            "Train Epoch: 2 [32500/60000 (54%)]\tLoss: 0.061861\n",
            "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.064012\n",
            "Train Epoch: 2 [33500/60000 (56%)]\tLoss: 0.172241\n",
            "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.080966\n",
            "Train Epoch: 2 [34500/60000 (58%)]\tLoss: 0.099593\n",
            "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.059819\n",
            "Train Epoch: 2 [35500/60000 (59%)]\tLoss: 0.189513\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.062751\n",
            "Train Epoch: 2 [36500/60000 (61%)]\tLoss: 0.059593\n",
            "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.030402\n",
            "Train Epoch: 2 [37500/60000 (62%)]\tLoss: 0.096549\n",
            "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.207332\n",
            "Train Epoch: 2 [38500/60000 (64%)]\tLoss: 0.078957\n",
            "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.108477\n",
            "Train Epoch: 2 [39500/60000 (66%)]\tLoss: 0.181537\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.147183\n",
            "Train Epoch: 2 [40500/60000 (68%)]\tLoss: 0.030245\n",
            "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.077932\n",
            "Train Epoch: 2 [41500/60000 (69%)]\tLoss: 0.063932\n",
            "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.028228\n",
            "Train Epoch: 2 [42500/60000 (71%)]\tLoss: 0.128947\n",
            "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.155596\n",
            "Train Epoch: 2 [43500/60000 (72%)]\tLoss: 0.271087\n",
            "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.020607\n",
            "Train Epoch: 2 [44500/60000 (74%)]\tLoss: 0.231834\n",
            "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.033342\n",
            "Train Epoch: 2 [45500/60000 (76%)]\tLoss: 0.277934\n",
            "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.190301\n",
            "Train Epoch: 2 [46500/60000 (78%)]\tLoss: 0.123429\n",
            "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.083724\n",
            "Train Epoch: 2 [47500/60000 (79%)]\tLoss: 0.122008\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.017760\n",
            "Train Epoch: 2 [48500/60000 (81%)]\tLoss: 0.124836\n",
            "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.114420\n",
            "Train Epoch: 2 [49500/60000 (82%)]\tLoss: 0.070500\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.101483\n",
            "Train Epoch: 2 [50500/60000 (84%)]\tLoss: 0.312595\n",
            "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.192896\n",
            "Train Epoch: 2 [51500/60000 (86%)]\tLoss: 0.087168\n",
            "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.123086\n",
            "Train Epoch: 2 [52500/60000 (88%)]\tLoss: 0.015699\n",
            "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.103392\n",
            "Train Epoch: 2 [53500/60000 (89%)]\tLoss: 0.115662\n",
            "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.267482\n",
            "Train Epoch: 2 [54500/60000 (91%)]\tLoss: 0.030171\n",
            "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.180385\n",
            "Train Epoch: 2 [55500/60000 (92%)]\tLoss: 0.091046\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.070686\n",
            "Train Epoch: 2 [56500/60000 (94%)]\tLoss: 0.043069\n",
            "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.121610\n",
            "Train Epoch: 2 [57500/60000 (96%)]\tLoss: 0.157287\n",
            "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.166013\n",
            "Train Epoch: 2 [58500/60000 (98%)]\tLoss: 0.120500\n",
            "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.055639\n",
            "Train Epoch: 2 [59500/60000 (99%)]\tLoss: 0.271855\n",
            "\n",
            "Test set: Avg. loss: 0.0798, Accuracy: 9741/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.105848\n",
            "Train Epoch: 3 [500/60000 (1%)]\tLoss: 0.047906\n",
            "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.095286\n",
            "Train Epoch: 3 [1500/60000 (2%)]\tLoss: 0.059538\n",
            "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.095918\n",
            "Train Epoch: 3 [2500/60000 (4%)]\tLoss: 0.073767\n",
            "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.061607\n",
            "Train Epoch: 3 [3500/60000 (6%)]\tLoss: 0.146366\n",
            "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.265345\n",
            "Train Epoch: 3 [4500/60000 (8%)]\tLoss: 0.134168\n",
            "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.215396\n",
            "Train Epoch: 3 [5500/60000 (9%)]\tLoss: 0.105316\n",
            "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.071034\n",
            "Train Epoch: 3 [6500/60000 (11%)]\tLoss: 0.129322\n",
            "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.025818\n",
            "Train Epoch: 3 [7500/60000 (12%)]\tLoss: 0.040031\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.054150\n",
            "Train Epoch: 3 [8500/60000 (14%)]\tLoss: 0.029019\n",
            "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.039139\n",
            "Train Epoch: 3 [9500/60000 (16%)]\tLoss: 0.076760\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.039118\n",
            "Train Epoch: 3 [10500/60000 (18%)]\tLoss: 0.055740\n",
            "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.063513\n",
            "Train Epoch: 3 [11500/60000 (19%)]\tLoss: 0.019233\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.130171\n",
            "Train Epoch: 3 [12500/60000 (21%)]\tLoss: 0.147485\n",
            "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.043083\n",
            "Train Epoch: 3 [13500/60000 (22%)]\tLoss: 0.055901\n",
            "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.194929\n",
            "Train Epoch: 3 [14500/60000 (24%)]\tLoss: 0.049798\n",
            "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.129209\n",
            "Train Epoch: 3 [15500/60000 (26%)]\tLoss: 0.064397\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.042817\n",
            "Train Epoch: 3 [16500/60000 (28%)]\tLoss: 0.167564\n",
            "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.037839\n",
            "Train Epoch: 3 [17500/60000 (29%)]\tLoss: 0.072747\n",
            "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.018032\n",
            "Train Epoch: 3 [18500/60000 (31%)]\tLoss: 0.112888\n",
            "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.113041\n",
            "Train Epoch: 3 [19500/60000 (32%)]\tLoss: 0.069028\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.023223\n",
            "Train Epoch: 3 [20500/60000 (34%)]\tLoss: 0.111873\n",
            "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.061552\n",
            "Train Epoch: 3 [21500/60000 (36%)]\tLoss: 0.111287\n",
            "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.049301\n",
            "Train Epoch: 3 [22500/60000 (38%)]\tLoss: 0.036986\n",
            "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.082541\n",
            "Train Epoch: 3 [23500/60000 (39%)]\tLoss: 0.115451\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.062666\n",
            "Train Epoch: 3 [24500/60000 (41%)]\tLoss: 0.043187\n",
            "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.050222\n",
            "Train Epoch: 3 [25500/60000 (42%)]\tLoss: 0.018537\n",
            "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.061796\n",
            "Train Epoch: 3 [26500/60000 (44%)]\tLoss: 0.125091\n",
            "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.235036\n",
            "Train Epoch: 3 [27500/60000 (46%)]\tLoss: 0.032521\n",
            "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.066549\n",
            "Train Epoch: 3 [28500/60000 (48%)]\tLoss: 0.025030\n",
            "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.129171\n",
            "Train Epoch: 3 [29500/60000 (49%)]\tLoss: 0.051812\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.031037\n",
            "Train Epoch: 3 [30500/60000 (51%)]\tLoss: 0.051406\n",
            "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.213166\n",
            "Train Epoch: 3 [31500/60000 (52%)]\tLoss: 0.014144\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.065751\n",
            "Train Epoch: 3 [32500/60000 (54%)]\tLoss: 0.028411\n",
            "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.040134\n",
            "Train Epoch: 3 [33500/60000 (56%)]\tLoss: 0.052249\n",
            "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.119871\n",
            "Train Epoch: 3 [34500/60000 (58%)]\tLoss: 0.028297\n",
            "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.067475\n",
            "Train Epoch: 3 [35500/60000 (59%)]\tLoss: 0.071438\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.067806\n",
            "Train Epoch: 3 [36500/60000 (61%)]\tLoss: 0.238911\n",
            "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.073213\n",
            "Train Epoch: 3 [37500/60000 (62%)]\tLoss: 0.082037\n",
            "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.043647\n",
            "Train Epoch: 3 [38500/60000 (64%)]\tLoss: 0.170532\n",
            "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.059630\n",
            "Train Epoch: 3 [39500/60000 (66%)]\tLoss: 0.076274\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.022717\n",
            "Train Epoch: 3 [40500/60000 (68%)]\tLoss: 0.080094\n",
            "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.105089\n",
            "Train Epoch: 3 [41500/60000 (69%)]\tLoss: 0.149936\n",
            "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.218332\n",
            "Train Epoch: 3 [42500/60000 (71%)]\tLoss: 0.096622\n",
            "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.065433\n",
            "Train Epoch: 3 [43500/60000 (72%)]\tLoss: 0.115312\n",
            "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.079553\n",
            "Train Epoch: 3 [44500/60000 (74%)]\tLoss: 0.036401\n",
            "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.065325\n",
            "Train Epoch: 3 [45500/60000 (76%)]\tLoss: 0.049125\n",
            "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.026133\n",
            "Train Epoch: 3 [46500/60000 (78%)]\tLoss: 0.055346\n",
            "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.031879\n",
            "Train Epoch: 3 [47500/60000 (79%)]\tLoss: 0.109555\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.079627\n",
            "Train Epoch: 3 [48500/60000 (81%)]\tLoss: 0.040460\n",
            "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.100956\n",
            "Train Epoch: 3 [49500/60000 (82%)]\tLoss: 0.004188\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.111557\n",
            "Train Epoch: 3 [50500/60000 (84%)]\tLoss: 0.066467\n",
            "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.115405\n",
            "Train Epoch: 3 [51500/60000 (86%)]\tLoss: 0.048337\n",
            "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.056011\n",
            "Train Epoch: 3 [52500/60000 (88%)]\tLoss: 0.109041\n",
            "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.025545\n",
            "Train Epoch: 3 [53500/60000 (89%)]\tLoss: 0.116607\n",
            "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.117389\n",
            "Train Epoch: 3 [54500/60000 (91%)]\tLoss: 0.065297\n",
            "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.140254\n",
            "Train Epoch: 3 [55500/60000 (92%)]\tLoss: 0.023694\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.105676\n",
            "Train Epoch: 3 [56500/60000 (94%)]\tLoss: 0.040822\n",
            "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.075732\n",
            "Train Epoch: 3 [57500/60000 (96%)]\tLoss: 0.203965\n",
            "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.201461\n",
            "Train Epoch: 3 [58500/60000 (98%)]\tLoss: 0.017614\n",
            "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.105707\n",
            "Train Epoch: 3 [59500/60000 (99%)]\tLoss: 0.154673\n",
            "\n",
            "Test set: Avg. loss: 0.0562, Accuracy: 9812/10000 (98%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model \n",
        "\n",
        "And there you have it. After merely 3 epochs of training, we have accomplished an impressive 97% accuracy on the test set. It's worth noting that at the beginning, when the parameters were randomly initialized, we achieved approximately 10% accuracy on the test set, which is exactly what we anticipated before initiating the training process.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4LezkKzz1rEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(train_counter, train_losses, color='blue')\n",
        "plt.scatter([0]+test_counter, test_losses, color='red')\n",
        "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "plt.xlabel('number of training examples seen')\n",
        "plt.ylabel('negative log likelihood loss')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "TnZRKJpR1_ee",
        "outputId": "63137f59-7a8b-4bc1-b3f7-d8da425a1076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'negative log likelihood loss')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3aLZ5KP0zGe",
        "outputId": "7ed21f34-ee4c-4034-97f4-b8b2c450a673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A_buOSi233Ss"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}